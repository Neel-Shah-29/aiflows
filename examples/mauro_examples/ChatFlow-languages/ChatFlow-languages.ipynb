{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7a649b1-e259-4b73-8df5-5dc7c28cae47",
   "metadata": {},
   "source": [
    "# ChatFlow Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "686be679-0b12-4675-8f25-67aaabc9c33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3290339a-e045-465a-a503-03dece48822a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2024-03-17 03:49:00,946\u001b[0m][\u001b[34maiflows.flow_verse.loading:775\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m[<interactive>]\u001b[0m started to sync flow module dependencies to /home/staverm/workspace/coflows-dev/aiflows/examples/mauro_examples/ChatFlow-languages/flow_modules...\u001b[0m\n",
      "[\u001b[36m2024-03-17 03:49:01,095\u001b[0m][\u001b[34maiflows.flow_verse.loading:608\u001b[0m][\u001b[32mINFO\u001b[0m] - aiflows/ChatFlowModule:coflows already synced, skip\u001b[0m\n",
      "[\u001b[36m2024-03-17 03:49:01,097\u001b[0m][\u001b[34maiflows.flow_verse.loading:825\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m[<interactive>]\u001b[0m finished syncing\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/staverm/workspace/coflows-dev/aiflows/examples/mauro_examples/ChatFlow-languages/flow_modules/aiflows/ChatFlowModule']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, json, copy\n",
    "\n",
    "from colink import CoLink\n",
    "\n",
    "from aiflows.utils import serve_utils\n",
    "from aiflows.utils.general_helpers import read_yaml_file\n",
    "from aiflows.messages import FlowMessage\n",
    "from aiflows.utils import coflows_utils, colink_utils\n",
    "from aiflows.workers import run_dispatch_worker_threads, run_dispatch_worker_thread\n",
    "from aiflows import flow_verse\n",
    "\n",
    "dependencies = [\n",
    "    {\"url\": \"aiflows/ChatFlowModule\", \"revision\": \"coflows\"},\n",
    "]\n",
    "flow_verse.sync_dependencies(dependencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a894bf-5605-4da7-984d-d0e06ee3288e",
   "metadata": {},
   "source": [
    "# Connect to CoLink Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa7d4186-d488-4a52-99d6-6a804cccd977",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = colink_utils.start_colink_server()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83270d6-93ad-4320-9821-506cef7969fc",
   "metadata": {},
   "source": [
    "# Start a few default workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b5e4f24-ed99-4d6a-af56-9c404bd43164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispatch worker started in attached thread.\n",
      "dispatch_point: coflows_dispatch\n",
      "\n",
      "~~~ Dispatch task ~~~\n",
      "flow_endpoint: Chatbot\n",
      "flow_id: 469b3425-87d6-4a58-9ae6-96ee6f7b299a\n",
      "message_paths: ['push_tasks:1cb5ce64-354a-4bfb-a3fc-0bbee5c09349:msg']\n",
      "parallel_dispatch: False\n",
      "\n",
      "\n",
      "~~~ Dispatch task ~~~\n",
      "flow_endpoint: Chatbot\n",
      "flow_id: 469b3425-87d6-4a58-9ae6-96ee6f7b299a\n",
      "message_paths: ['push_tasks:78046133-4082-4f06-bf4e-2c0a74bc69bd:msg']\n",
      "parallel_dispatch: False\n",
      "\n",
      "[\u001b[36m2024-03-17 03:49:09,380\u001b[0m][\u001b[34maiflows.utils.general_helpers:387\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1m\u001b[31m \n",
      "\n",
      "For feedback or to get help:  \u001b[0m\u001b[1m\u001b[32mhttps://github.com/epfl-dlab/aiflows/issues \n",
      "\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-03-17 03:49:09,382\u001b[0m][\u001b[34maiflows.utils.general_helpers:397\u001b[0m][\u001b[31mERROR\u001b[0m] - 'query'\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/staverm/workspace/coflows-dev/aiflows/aiflows/utils/general_helpers.py\", line 406, in wrapper\n",
      "    return f(*args, **kw)\n",
      "  File \"/home/staverm/workspace/coflows-dev/aiflows/aiflows/base_flows/abstract.py\", line 535, in __call__\n",
      "    self._run_method(input_message)\n",
      "  File \"/home/staverm/workspace/coflows-dev/aiflows/aiflows/base_flows/abstract.py\", line 520, in _run_method\n",
      "    self.run(input_message)\n",
      "  File \"/home/staverm/workspace/coflows-dev/aiflows/examples/mauro_examples/ChatFlow-languages/flow_modules/aiflows/ChatFlowModule/ChatAtomicFlow.py\", line 394, in run\n",
      "    response = self.query_llm(input_data=input_data)\n",
      "  File \"/home/staverm/workspace/coflows-dev/aiflows/examples/mauro_examples/ChatFlow-languages/flow_modules/aiflows/ChatFlowModule/ChatAtomicFlow.py\", line 372, in query_llm\n",
      "    self._process_input(input_data)\n",
      "  File \"/home/staverm/workspace/coflows-dev/aiflows/examples/mauro_examples/ChatFlow-languages/flow_modules/aiflows/ChatFlowModule/ChatAtomicFlow.py\", line 347, in _process_input\n",
      "    user_message_content = self._get_message(self.human_message_prompt_template, input_data)\n",
      "  File \"/home/staverm/workspace/coflows-dev/aiflows/examples/mauro_examples/ChatFlow-languages/flow_modules/aiflows/ChatFlowModule/ChatAtomicFlow.py\", line 219, in _get_message\n",
      "    template_kwargs[input_variable] = input_data[input_variable]\n",
      "KeyError: 'query'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5 (run):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/staverm/.pyenv/versions/3.10.6/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/staverm/.pyenv/versions/3.10.6/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 761, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/home/staverm/.pyenv/versions/3.10.6/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/staverm/workspace/coflows-dev/colink-sdk-python-dev/colink/protocol.py\", line 128, in run\n",
      "    raise err\n",
      "  File \"/home/staverm/workspace/coflows-dev/colink-sdk-python-dev/colink/protocol.py\", line 20, in thread_func\n",
      "    cl_app.start()\n",
      "  File \"/home/staverm/workspace/coflows-dev/colink-sdk-python-dev/colink/protocol.py\", line 220, in start\n",
      "    raise e\n",
      "  File \"/home/staverm/workspace/coflows-dev/colink-sdk-python-dev/colink/protocol.py\", line 213, in start\n",
      "    self.user_func(cl, task.protocol_param, task.participants)\n",
      "  File \"/home/staverm/workspace/coflows-dev/aiflows/aiflows/workers/dispatch_worker.py\", line 164, in dispatch_task_handler\n",
      "    flow(input_msg)\n",
      "  File \"/home/staverm/workspace/coflows-dev/aiflows/aiflows/utils/general_helpers.py\", line 408, in wrapper\n",
      "    exception_handler(e)\n",
      "  File \"/home/staverm/workspace/coflows-dev/aiflows/aiflows/utils/general_helpers.py\", line 398, in exception_handler\n",
      "    raise e\n",
      "  File \"/home/staverm/workspace/coflows-dev/aiflows/aiflows/utils/general_helpers.py\", line 406, in wrapper\n",
      "    return f(*args, **kw)\n",
      "  File \"/home/staverm/workspace/coflows-dev/aiflows/aiflows/base_flows/abstract.py\", line 535, in __call__\n",
      "    self._run_method(input_message)\n",
      "  File \"/home/staverm/workspace/coflows-dev/aiflows/aiflows/base_flows/abstract.py\", line 520, in _run_method\n",
      "    self.run(input_message)  \n",
      "  File \"/home/staverm/workspace/coflows-dev/aiflows/examples/mauro_examples/ChatFlow-languages/flow_modules/aiflows/ChatFlowModule/ChatAtomicFlow.py\", line 394, in run\n",
      "    response = self.query_llm(input_data=input_data)\n",
      "  File \"/home/staverm/workspace/coflows-dev/aiflows/examples/mauro_examples/ChatFlow-languages/flow_modules/aiflows/ChatFlowModule/ChatAtomicFlow.py\", line 372, in query_llm\n",
      "    self._process_input(input_data)\n",
      "  File \"/home/staverm/workspace/coflows-dev/aiflows/examples/mauro_examples/ChatFlow-languages/flow_modules/aiflows/ChatFlowModule/ChatAtomicFlow.py\", line 347, in _process_input\n",
      "    user_message_content = self._get_message(self.human_message_prompt_template, input_data)\n",
      "  File \"/home/staverm/workspace/coflows-dev/aiflows/examples/mauro_examples/ChatFlow-languages/flow_modules/aiflows/ChatFlowModule/ChatAtomicFlow.py\", line 219, in _get_message\n",
      "    template_kwargs[input_variable] = input_data[input_variable]\n",
      "KeyError: 'query'\n"
     ]
    }
   ],
   "source": [
    "run_dispatch_worker_thread(cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae53237c-1f4b-4f15-a8a8-d8ad01788264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispatch worker started in attached thread.\n",
      "dispatch_point: coflows_dispatch\n",
      "\n",
      "~~~ Dispatch task ~~~\n",
      "flow_endpoint: Chatbot\n",
      "flow_id: 469b3425-87d6-4a58-9ae6-96ee6f7b299a\n",
      "message_paths: ['push_tasks:8c80b814-7368-4f07-8a2b-d5b4a897f92b:msg']\n",
      "parallel_dispatch: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_dispatch_worker_thread(cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e623d0b4-1501-4460-bc5f-a1aeb590eefc",
   "metadata": {},
   "source": [
    "# Serve ChatFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd960cb9-4b24-4b2f-b374-0b3c89e7dd55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started serving flow_modules.aiflows.ChatFlowModule.ChatAtomicFlow at flows:Chatbot.\n",
      "dispatch_point: coflows_dispatch\n",
      "parallel_dispatch: False\n",
      "singleton: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serve_utils.serve_flow(\n",
    "    cl=cl,\n",
    "    flow_class_name=\"flow_modules.aiflows.ChatFlowModule.ChatAtomicFlow\",\n",
    "    flow_endpoint=\"Chatbot\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c1addd-333e-4917-8170-8237b4ee307e",
   "metadata": {},
   "source": [
    "## Get two instances with different configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a48d217d-c034-4588-9389-373cd954c0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \".\"\n",
    "cfg_path = os.path.join(root_dir, \"flow_modules/aiflows/ChatFlowModule/demo.yaml\")\n",
    "cfg = read_yaml_file(cfg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfd8d59c-138a-47a7-97ad-e6393f1c909d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted 469b3425-87d6-4a58-9ae6-96ee6f7b299a at flows:Chatbot:mounts:local:469b3425-87d6-4a58-9ae6-96ee6f7b299a\n"
     ]
    }
   ],
   "source": [
    "args_A = copy.deepcopy(cfg)\n",
    "args_A[\"system_message_prompt_template\"][\"template\"] = \\\n",
    "\"You are a helpful chatbot that truthfully answers questions. Answer in the language English.\"\n",
    "\n",
    "chatbot_A = serve_utils.get_flow_instance(\n",
    "    cl=cl,\n",
    "    flow_endpoint=\"Chatbot\",\n",
    "    config_overrides=args_A,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e832b8f-bd48-490c-af76-9cd5dbcc8a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched singleton 469b3425-87d6-4a58-9ae6-96ee6f7b299a\n"
     ]
    }
   ],
   "source": [
    "args_B = copy.deepcopy(cfg)\n",
    "args_B[\"system_message_prompt_template\"][\"template\"] = \\\n",
    "\"You are a helpful chatbot that truthfully answers questions. Answer in the language Croatian.\"\n",
    "\n",
    "\n",
    "chatbot_B = serve_utils.get_flow_instance(\n",
    "    cl=cl,\n",
    "    flow_endpoint=\"Chatbot\",\n",
    "    config_overrides=args_B,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c250e8-7b3b-42e7-9eb0-4199a45e2680",
   "metadata": {},
   "source": [
    "## Conversation with chatbot A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0634e733-354f-42ff-90c4-d279895ae6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'api_output': 'The capital of Switzerland is Bern.'}\n",
      "{'api_output': 'Bern, the capital of Switzerland, is located in the central part of the country, on the Swiss Plateau.'}\n"
     ]
    }
   ],
   "source": [
    "input_message = FlowMessage(\n",
    "    data={\"id\": 0, \"question\": \"What is the capital of Switzerland?\"},\n",
    ")\n",
    "\n",
    "future = chatbot_A.get_reply_future(input_message)\n",
    "print(future.get_data())\n",
    "\n",
    "input_message = FlowMessage(\n",
    "    data={\"id\": 0, \"query\": \"Where is it located?\"},\n",
    ")\n",
    "\n",
    "future = chatbot_A.get_reply_future(input_message)\n",
    "print(future.get_data())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb34896-6fe0-403a-a95e-abed132a72a3",
   "metadata": {},
   "source": [
    "## Conversation with chatbot B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa4a9b8-a47b-4fee-8bce-3b4ed404ca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = FlowMessage(\n",
    "    data={\"id\": 0, \"question\": \"What is the capital of Switzerland?\"},\n",
    ")\n",
    "\n",
    "future = chatbot_B.get_reply_future(input_message)\n",
    "print(future.get_data())\n",
    "\n",
    "input_message = FlowMessage(\n",
    "    data={\"id\": 0, \"query\": \"Where is it located?\"},\n",
    ")\n",
    "\n",
    "future = chatbot_B.get_reply_future(input_message)\n",
    "print(future.get_data())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
