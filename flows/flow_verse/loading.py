import os
import re
import sys
import shutil
import inspect
import filecmp
from typing import List, Dict, Tuple
from collections import namedtuple

import colorama
import huggingface_hub
from huggingface_hub.hf_api import HfApi

from flows.utils import logging

logger = logging.get_logger(__name__)

default_home = os.path.join(os.path.expanduser("~"), ".cache")
flows_cache_home = os.path.expanduser(os.path.join(default_home, "flows"))
DEFAULT_CACHE_PATH = os.path.join(flows_cache_home, "flow_verse")
DEFAULT_FLOW_MODULE_FOLDER = "flow_modules"
MODULE_ID_FILE_NAME = "FLOW_MODULE_ID"
REVISION_FILE_HEADER = """\
########################################
# auto-generated by flows, DO NOT EDIT #
########################################
"""
DEFAULT_REMOTE_REVISION = "main"

FlowModuleSpec = namedtuple("FlowModuleSpec", ["mod_id", "repo_id", "revision", "commit_hash", "cache_dir"])
INVALID_FLOW_MOD_SPEC = FlowModuleSpec(None, None, None, None, None)

def add_to_sys_path(path):
    # Make sure the path is absolute
    absolute_path = os.path.abspath(path)

    # Check if the path is in sys.path
    if absolute_path not in sys.path:
        # If it's not, add it
        sys.path.append(absolute_path)


add_to_sys_path(f"./{DEFAULT_FLOW_MODULE_FOLDER}")

# TODO(yeeef): add a check to make sure the module name is valid
def _is_valid_python_module_name(name):
    return re.match(r'^[a-zA-Z_][a-zA-Z0-9_]*$', name) is not None

# TODO(Yeeef): caller_module_name is shared at several places, so we should refactor the sync process into
# a class.
def _validate_and_augment_dependency(dependency: Dict[str, str], caller_module_name: str):
    if "url" not in dependency: # TODO(yeeef): url is not descriptive
        raise ValueError("dependency must have a `url` field")

    match = re.search(r"^(\w+)/(\w+)$", dependency["url"])
    if not match:
        raise ValueError("dependency url must be in the format of `username/repo_name`(huggingface repo)")
    username, repo_name = match.group(1), match.group(2)

    if re.search(r"^\d+\w+$", repo_name): # repo_name is prefixed with a number
        raise ValueError(f"url's repo name `{repo_name}` is prefixed with a number, which is illegal in Flows, please adjust your repo name")
    
    if re.search(r"^\d+\w+$", username): # username is prefixed with a number
        
        logger.warning(f"[{caller_module_name}] url's username `{username}` is prefixed with a number, which is not a valid python module name, the module will be synced to ./flow_modules/user_{username}.{repo_name}, please import it as `import flow_modules.user_{username}.{repo_name}`")
        username = f"user_{username}"

    dependency["mod_name"] = f"{username}/{repo_name}"
    if "revision" not in dependency:
        dependency["revision"] = DEFAULT_REMOTE_REVISION

    return dependency

def _write_or_append_gitignore(sync_dir: str, mode: str, content: str):
    gitignore_path = os.path.join(sync_dir, ".gitignore")
    
    if os.path.exists(gitignore_path):
        with open(gitignore_path, "r") as gitignore_f:
            if content in gitignore_f.read():
                return

    with open(gitignore_path, mode) as gitignore_f:
        lines = [
            "\n\n\n# auto-generated by flows, all synced modules will be ignored by default\n",
            f"{content}\n"
        ]
        gitignore_f.writelines(lines)

def _remove_dir_or_link(sync_dir: str):
    if os.path.islink(sync_dir):
        os.remove(sync_dir)
    elif os.path.isdir(sync_dir): # it need to be decided after islink, because isdir is also True for link
        shutil.rmtree(sync_dir)
    else:
        raise ValueError(f"Invalid sync_dir: {sync_dir}, it is not a valid directory nor a valid link")

# TODO(Yeeef): add repo_hash and modified_flag to decrease computing
def _write_flow_mod_spec(sync_dir: str, flow_mod_spec: FlowModuleSpec):
    revision_file_path = os.path.join(sync_dir, MODULE_ID_FILE_NAME)
    with open(revision_file_path, "w") as revision_f:
        lines = [
            REVISION_FILE_HEADER,
            flow_mod_spec.mod_id + "\n", # xxx/yyy:{revision}
            flow_mod_spec.commit_hash + "\n", # commithash corresponding to the revision
            flow_mod_spec.cache_dir + "\n", # huggingface cache_dir
        ]
        revision_f.writelines(lines)

def _read_flow_mod_spec(sync_dir: str) -> FlowModuleSpec:
    revision_file_path = os.path.join(sync_dir, MODULE_ID_FILE_NAME)
    if not os.path.exists(revision_file_path):
        return INVALID_FLOW_MOD_SPEC

    with open(revision_file_path, "r") as revision_f:
        lines = revision_f.readlines()
        if len(lines) != 6: # 3 lines of header + flow_mod_id + commit_hash + cache_dir 
            return INVALID_FLOW_MOD_SPEC

        if "".join(lines[:3]) != REVISION_FILE_HEADER: # check header
            return INVALID_FLOW_MOD_SPEC

        flow_mod_id = lines[3].strip()
        repo_id, revision = flow_mod_id.split(":")
        commit_hash = lines[4].strip()
        cache_dir = lines[5].strip()
        return FlowModuleSpec(flow_mod_id, repo_id, revision, commit_hash, cache_dir)

def _fetch_remote(repo_id: str, revision: str, cache_root_dir: str, sync_dir: str) -> Tuple[str, str]:
    
    sync_dir = os.path.abspath(sync_dir)
    if _is_local_sync_dir_valid(sync_dir):
        _remove_dir_or_link(sync_dir)

    os.makedirs(os.path.dirname(sync_dir), exist_ok=True)
    # this call is only used to download the repo to cache and get cache path
    cache_mod_dir = huggingface_hub.snapshot_download(repo_id, cache_dir=cache_root_dir, revision=revision)

    # this call will fetch the cached snapshot to the sync_dir
    huggingface_hub.snapshot_download(repo_id, cache_dir=cache_root_dir, local_dir=sync_dir, revision=revision)
    return cache_mod_dir, _retrive_commit_hash(repo_id, revision)

def _fetch_remote_and_write_flow_mod_spec(repo_id: str, revision: str, flow_mod_id: str, sync_dir: str):
    cache_dir, commit_hash = _fetch_remote(repo_id, revision, DEFAULT_CACHE_PATH, sync_dir)
    _write_flow_mod_spec(
        sync_dir, FlowModuleSpec(flow_mod_id, repo_id, revision, commit_hash, cache_dir)
    )
    _write_or_append_gitignore(sync_dir, "a", MODULE_ID_FILE_NAME)

def _fetch_local_and_write_flow_mod_spec(repo_id: str, file_path: str, flow_mod_id: str, sync_dir: str):
    # shutil.copytree(file_path, sync_dir, ignore=shutil.ignore_patterns(".git"), dirs_exist_ok=overwrite)
    sync_dir = os.path.abspath(sync_dir)
    # when fetch_local is triggered, the old dir is always going to be removed
    if _is_local_sync_dir_valid(sync_dir):
        _remove_dir_or_link(sync_dir)

    os.makedirs(os.path.dirname(sync_dir), exist_ok=True)
    os.symlink(file_path, sync_dir)
    _write_flow_mod_spec(
        sync_dir, FlowModuleSpec(flow_mod_id, repo_id, file_path, "no_commit_hash", file_path)
    )
    _write_or_append_gitignore(sync_dir, "a", MODULE_ID_FILE_NAME)

def _build_mod_id(repo_id_or_file_path: str, revision: str):
    return f"{repo_id_or_file_path}:{revision}"

def _is_local_sync_dir_valid(sync_dir: str):
    return os.path.isdir(sync_dir) or os.path.islink(sync_dir)

def _retrive_commit_hash(repo_id: str, revision: str):
    hf_api = HfApi()
    repo_info = hf_api.repo_info(repo_id=repo_id, repo_type="model", revision=revision, token=None)
    commit_hash = repo_info.sha
    return commit_hash

def _is_sync_dir_modified(sync_dir: str, cache_dir: str) -> bool:
    with os.scandir(cache_dir) as it:
        for entry in it:
            if entry.name.startswith('.') or entry.name == "__pycache__":
                continue

            if entry.is_file():
                same = filecmp.cmp(
                    os.path.join(cache_dir, entry.name), 
                    os.path.join(sync_dir, entry.name),
                    shallow=False
                )
                if not same:
                    logger.debug(f"File {os.path.join(cache_dir, entry.name)} is not the same as {os.path.join(sync_dir, entry.name)}")
                    return True
            elif entry.is_dir():
                dir_same = _is_sync_dir_modified(
                    os.path.join(sync_dir, entry.name), 
                    os.path.join(cache_dir, entry.name)
                )
                if not dir_same:
                    return True
            else:
                raise ValueError(f"Invalid file: {os.path.join(cache_dir, entry.name)}, it is not file or dir or valid symlink")
            
    return False
            

def _sync_remote_dep(repo_id: str, mod_name: str, revision: str, caller_module_name: str, overwrite: bool = False) -> str:
    flow_mod_id = _build_mod_id(repo_id, revision)
    sync_dir = os.path.join(os.path.curdir, DEFAULT_FLOW_MODULE_FOLDER, mod_name)

    if overwrite:
        logger.warn(f"{colorama.Fore.RED}[{caller_module_name}] {flow_mod_id} will be overwritten, are you sure? (Y/N){colorama.Style.RESET_ALL}")
        user_input = input()
        if user_input != "Y":
            logger.warn(f"{colorama.Fore.RED}[{caller_module_name}] {flow_mod_id} will not be overwritten.{colorama.Style.RESET_ALL}")
            overwrite = False

    # read current flow spec
    synced_flow_mod_spec = _read_flow_mod_spec(sync_dir)

    # no valid flow spec, we fetch the remote directly
    # overwrite is True, we fetch the remote directly
    if synced_flow_mod_spec == INVALID_FLOW_MOD_SPEC or overwrite: 
        logger.info(f"{flow_mod_id} will be fetched from remote.{colorama.Style.RESET_ALL}")
        _fetch_remote_and_write_flow_mod_spec(repo_id, revision, flow_mod_id, sync_dir)
        return sync_dir
    
    # user has supplied a new flow_mod_id, we fetch the remote directly with warning
    if synced_flow_mod_spec.mod_id != flow_mod_id:
        logger.warn(
                f"{colorama.Fore.RED}[{caller_module_name}] {synced_flow_mod_spec.mod_id} already synced, it will be overwritten by new revision {flow_mod_id}, are you sure? (Y/N){colorama.Style.RESET_ALL}")
        user_input = input()
        if user_input != "Y":
            logger.warn(f"{colorama.Fore.RED}[{caller_module_name}] {flow_mod_id} will not be overwritten.{colorama.Style.RESET_ALL}")
        else:
            _fetch_remote_and_write_flow_mod_spec(repo_id, revision, flow_mod_id, sync_dir)

        return sync_dir
    

    # user has supplied same flow_mod_id, we check if the remote has changed

    # check if the commit hash changes from the remote
    remote_revision_commit_hash_changed = False
    # TODO(yeeef): _retrive_commit_hash is slow
    remote_commit_hash = _retrive_commit_hash(synced_flow_mod_spec.repo_id, synced_flow_mod_spec.revision)
    remote_revision_commit_hash_changed = remote_commit_hash != synced_flow_mod_spec.commit_hash

    # check if the file is modified compared to the cache_dir
    sync_dir_modified = _is_sync_dir_modified(sync_dir, synced_flow_mod_spec.cache_dir)

    logger.debug(f"{flow_mod_id} remote_revision_commit_hash_changed: {remote_revision_commit_hash_changed}, sync_dir_modified: {sync_dir_modified}")
    # sync_dir is not modified but remote_commit_hash hash has changed
    # we do nothing, with a warning message
    if not remote_revision_commit_hash_changed:
        # trivial case, we do nothing
        logger.info(f"{flow_mod_id} already synced, skip")
    elif not sync_dir_modified:
        # remote has changed but local is not modified, we fetch the remote with a warning
        logger.warn(f"{colorama.Fore.RED}[{caller_module_name}] {synced_flow_mod_spec.mod_id}'s commit hash has changed from {synced_flow_mod_spec.commit_hash} to {remote_commit_hash}, as synced module is not modified, the newest commit regarding {synced_flow_mod_spec.mod_id} will be fetched{colorama.Style.RESET_ALL}")
        _fetch_remote_and_write_flow_mod_spec(repo_id, revision, flow_mod_id, sync_dir)
    else: 
        # synced dir is modified and remote has changed, we do nothing with a warning
        logger.warn(f"{colorama.Fore.RED}[{caller_module_name}] {synced_flow_mod_spec.mod_id}'s commit hash has changed from {synced_flow_mod_spec.commit_hash} to {remote_commit_hash}, but synced module is already modified, the newest commit regarding {synced_flow_mod_spec.mod_id} will NOT be fetched{colorama.Style.RESET_ALL}")
        
    return sync_dir 

def _sync_local_dep(repo_id: str, mod_name: str, revision: str, caller_module_name: str, overwrite: bool = False) -> str:
    flow_mod_id = _build_mod_id(repo_id, revision)
    if overwrite:
        logger.warn(f"{colorama.Fore.RED}[{caller_module_name}] {flow_mod_id} will be overwritten, are you sure? (Y/N){colorama.Style.RESET_ALL}")
        user_input = input()
        if user_input != "Y":
            logger.warn(f"{colorama.Fore.RED}[{caller_module_name}] {flow_mod_id} will not be overwritten.{colorama.Style.RESET_ALL}")
            overwrite = False

    module_local_dir = revision

    if not os.path.isdir(module_local_dir):
        raise ValueError(f"local dependency {flow_mod_id}'s revision {revision} is not a valid local directory")
    
    sync_dir = os.path.join(os.path.curdir, DEFAULT_FLOW_MODULE_FOLDER, mod_name)
    synced_flow_mod_spec = _read_flow_mod_spec(sync_dir)

    if synced_flow_mod_spec == INVALID_FLOW_MOD_SPEC or overwrite:
        logger.info(f"{flow_mod_id} will be fetched from local.{colorama.Style.RESET_ALL}")
        _fetch_local_and_write_flow_mod_spec(repo_id, revision, flow_mod_id, sync_dir)
        return sync_dir
    elif synced_flow_mod_spec.mod_id != flow_mod_id:
        logger.warn(
            f"{colorama.Fore.RED}[{caller_module_name}] {synced_flow_mod_spec.mod_id} already synced, it will be overwritten by new revision {flow_mod_id}, are you sure? (Y/N){colorama.Style.RESET_ALL}")
        user_input = input()
        if user_input != "Y":
            logger.warn(f"{colorama.Fore.RED}[{caller_module_name}] {flow_mod_id} will not be overwritten.{colorama.Style.RESET_ALL}")
        else:
            _fetch_local_and_write_flow_mod_spec(repo_id, revision, flow_mod_id, sync_dir)
    else:
        logger.info(f"{flow_mod_id} already synced, skip")
    
        
    return sync_dir


def sync_dependencies(dependencies: List[Dict[str, str]], all_overwrite: bool = False):
    caller_frame = inspect.currentframe().f_back
    caller_module = inspect.getmodule(caller_frame)
    if caller_module is None: # TODO: https://github.com/epfl-dlab/flows/issues/50
        caller_module_name = "<interactive>"
    else:
        caller_module_name = caller_module.__name__
    
    logger.info(
        f"{colorama.Fore.GREEN}[{caller_module_name}]{colorama.Style.RESET_ALL} started to sync flow module dependencies...")
    flow_module_dir = os.path.join(os.path.curdir, DEFAULT_FLOW_MODULE_FOLDER)
    if not os.path.exists(flow_module_dir):
        os.mkdir(flow_module_dir)
    elif not os.path.isdir(flow_module_dir):
        raise ValueError(f"flow module folder {flow_module_dir} is not a directory")

    _write_or_append_gitignore(flow_module_dir, "w", content="*")

    sync_dirs = []
    for dep in dependencies:
        dep = _validate_and_augment_dependency(dep, caller_module_name)
        dep_overwrite = dep.get("overwrite", False)
        dep_is_local = False
        url, revision, mod_name = dep["url"], dep["revision"], dep["mod_name"]
        sync_dir = None

        if os.path.exists(revision): # revision point to a local path
            dep_is_local = True
            revision = os.path.abspath(revision)
            if DEFAULT_FLOW_MODULE_FOLDER in revision:
                raise ValueError(f"syncing a local revision from {DEFAULT_FLOW_MODULE_FOLDER} is not recommended")
        else:
            match = re.search(r"\W", revision)  # ToDo (Martin): This often fails with a cryptic error message
            if match is not None:
                raise ValueError(f"{revision} is identified as remote, as it does not exist locally. But it not a valid remote revision, it contains illegal characters: {match.group(0)}")

        if dep_is_local:
            sync_dir = _sync_local_dep(url, mod_name, revision, caller_module_name, all_overwrite or dep_overwrite)
        else:
            sync_dir = _sync_remote_dep(url, mod_name, revision, caller_module_name, all_overwrite or dep_overwrite)
        sync_dirs.append(sync_dir)

    logger.info(f"{colorama.Fore.GREEN}[{caller_module_name}]{colorama.Style.RESET_ALL} finished syncing\n\n")
    return sync_dirs
