import os
import re
import sys
import shutil
import inspect
import filecmp
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass


import colorama
import huggingface_hub
from huggingface_hub.hf_api import HfApi

from flows.utils import logging

from . import utils

logger = logging.get_logger(__name__)

default_home = os.path.join(os.path.expanduser("~"), ".cache")
flows_cache_home = os.path.expanduser(os.path.join(default_home, "flows"))
DEFAULT_CACHE_PATH = os.path.join(flows_cache_home, "flow_verse")
DEFAULT_FLOW_MODULE_FOLDER = "flow_modules"
MODULE_ID_FILE_NAME = "FLOW_MODULE_ID"
FLOW_MODULE_SUMMARY_FILE_NAME = "flow.mod"
REVISION_FILE_HEADER = """\
########################################
# auto-generated by flows, DO NOT EDIT #
########################################\
"""

DEFAULT_REMOTE_REVISION = "main"
NO_COMMIT_HASH = "NO_COMMIT_HASH"


@dataclass
class FlowModuleSpec:
    repo_id: str
    revision: str
    commit_hash: str
    cache_dir: str
    sync_dir: str

    @staticmethod
    def build_mod_id(repo_id: str, revision: str):
        return f"{repo_id}:{revision}"

    @property
    def mod_id(self):
        return self.build_mod_id(self.repo_id, self.revision)

"""
########################################
# auto-generated by flows, DO NOT EDIT #
########################################
sync_root: xxxx
saibo/aaaa {revision} {commit_hash} -> _/saibo/aaaa
3Represent/bbbb {revision} {commit_hash} -> _/user_3Represent/bbbb
"""

# TODO(yeeef): huggingface username spec: Letters, numbers, dashes. No dash at the end or the start, no consecutive dashes. Not just numbers.; r"^(?!-)(?!.*-$)(?!.*--)[a-zA-Z0-9-]+(?<!^\d+)$"
#       model name spec: Only regular alphanumeric characters, '-', ' and '_' supported; r"^[a-zA-Z0-9\-_' ]+$"

# TODO(yeeef): lock to protect the singleton

"""
flow module data model

in flow.mod
keyed by repo_id, for each repo_id, we only preserve one (revision+commit_hash); we only preserve one version for each repo_id

flow_mod_id: repo_id:revision (it is still not unique, as same revision might corresponds to differernt commit hash, but it is a user-friendly format)
"""

class FlowModuleSpecSummary:
    def __init__(self, sync_root: str, mods: List[FlowModuleSpec] = None) -> None:
        if mods is None:
            mods = []
        self._sync_root = sync_root
        self._mods = {mod.repo_id: mod for mod in mods}

    def add_mod(self, flow_mod_spec: FlowModuleSpec):
        """
        Adds a FlowModuleSpec object to the FlowModuleSpecSummary object.

        :param flow_mod_spec: The FlowModuleSpec object to be added.
        :type flow_mod_spec: FlowModuleSpec
        """
        self._mods[flow_mod_spec.repo_id] = flow_mod_spec

    def get_mod(self, repo_id: str) -> Optional[FlowModuleSpec]:
        """
        Returns the `FlowModuleSpec` object for the specified repository ID.

        :param repo_id: The repository ID.
        :type repo_id: str
        :return: The `FlowModuleSpec` object for the specified repository ID, or `None` if not found.
        :rtype: Optional[FlowModuleSpec]
        """
        return self._mods.get(repo_id, None)

    @staticmethod
    def from_flow_mod_file(file_path: str) -> Optional["FlowModuleSpecSummary"]:
        """
        Reads a flow module file and returns a `FlowModuleSpecSummary` object.

        :param file_path: The path to the flow module file.
        :type file_path: str
        :return: A `FlowModuleSpecSummary` object if the file exists, otherwise `None`.
        :rtype: Optional["FlowModuleSpecSummary"]
        :raises ValueError: If the flow module file is invalid.
        """        
        
        sync_root_pattern = re.compile(r"^sync_root: (.+)$")
        flow_mod_spec_match = re.compile(r"^(\w+)/(\w+) (\w+) (\w+) -> _/(.+)$")
        if not os.path.exists(file_path):
            return None
        
        with open(file_path, "r") as f:
            lines = [line.strip() for line in f.readlines()]
            if len(lines) < 1 + len(REVISION_FILE_HEADER.split("\n")):
                raise ValueError(f"Invalid flow module file {file_path}, at least 1 line is required for `sync_root`")

            sync_root_match = re.search(sync_root_pattern, lines[0])
            if not sync_root_match:
                raise ValueError(f"Invalid flow module file {file_path}, the first line must be `sync_root: xxxx`")
            sync_root = sync_root_match.group(1)

            mods = []
            for line in lines[4:]:
                flow_mod_spec_match = re.search(flow_mod_spec_match, line)
                if not flow_mod_spec_match:
                    continue
                username, repo_name, revision, commit_hash, relative_sync_dir = flow_mod_spec_match.groups()
                repo_id = f"{username}/{repo_name}"
                cache_dir = utils.build_hf_cache_path(username, repo_name, commit_hash, flows_cache_home)
                sync_dir = os.path.join(sync_root, relative_sync_dir)
                flow_mod_spec = FlowModuleSpec(repo_id, revision, commit_hash, cache_dir, sync_dir)
                mods.append(flow_mod_spec)


            return FlowModuleSpecSummary(sync_root, mods)
    
    def serialize(self) -> str:
        lines = []
        lines.append(f"sync_root: {self._sync_root}")
        for mod in self._mods:
            lines.append(f"{mod.repo_id} {mod.revision} {mod.commit_hash} -> _/{os.path.relpath(mod.sync_dir, self._sync_root)}")

        return "\n".join(lines)
    
    def __repr__(self) -> str:
        return f"~~~ FlowModuleSpecSummary ~~~\n{self.serialize()}"
    
    def __str__(self) -> str:
        return self.__repr__()

def add_to_sys_path(path):
    # Make sure the path is absolute
    absolute_path = os.path.abspath(path)

    # Check if the path is in sys.path
    if absolute_path not in sys.path:
        # If it's not, add it
        sys.path.append(absolute_path)


add_to_sys_path(f"./{DEFAULT_FLOW_MODULE_FOLDER}")

# TODO(yeeef): add a check to make sure the module name is valid
def _is_valid_python_module_name(name):
    return re.match(r'^[a-zA-Z_][a-zA-Z0-9_]*$', name) is not None

# TODO(Yeeef): caller_module_name is shared at several places, so we should refactor the sync process into
# a class.
def validate_and_augment_dependency(dependency: Dict[str, str], caller_module_name: str):
    if "url" not in dependency: # TODO(yeeef): url is not descriptive
        raise ValueError("dependency must have a `url` field")

    match = re.search(r"^(\w+)/(\w+)$", dependency["url"])
    if not match:
        raise ValueError("dependency url must be in the format of `username/repo_name`(huggingface repo)")
    username, repo_name = match.group(1), match.group(2)

    if re.search(r"^\d+\w+$", repo_name): # repo_name is prefixed with a number
        raise ValueError(f"url's repo name `{repo_name}` is prefixed with a number, which is illegal in Flows, please adjust your repo name")
    
    if re.search(r"^\d+\w+$", username): # username is prefixed with a number
        
        logger.warning(f"[{caller_module_name}] url's username `{username}` is prefixed with a number, which is not a valid python module name, the module will be synced to ./flow_modules/user_{username}.{repo_name}, please import it as `import flow_modules.user_{username}.{repo_name}`")
        username = f"user_{username}"

    dependency["mod_name"] = f"{username}/{repo_name}"
    if "revision" not in dependency:
        dependency["revision"] = DEFAULT_REMOTE_REVISION

    return dependency

def write_or_append_gitignore(sync_dir: str, mode: str, content: str):
    gitignore_path = os.path.join(sync_dir, ".gitignore")
    
    if os.path.exists(gitignore_path):
        with open(gitignore_path, "r") as gitignore_f:
            if content in gitignore_f.read():
                return

    with open(gitignore_path, mode) as gitignore_f:
        lines = [
            "\n\n\n# auto-generated by flows, all synced modules will be ignored by default\n",
            f"{content}\n"
        ]
        gitignore_f.writelines(lines)

def remove_dir_or_link(sync_dir: str):
    if os.path.islink(sync_dir):
        os.remove(sync_dir)
    elif os.path.isdir(sync_dir): # it need to be decided after islink, because isdir is also True for link
        shutil.rmtree(sync_dir)
    else:
        raise ValueError(f"Invalid sync_dir: {sync_dir}, it is not a valid directory nor a valid link")

# # TODO(Yeeef): add repo_hash and modified_flag to decrease computing
# def _write_flow_mod_spec(sync_dir: str, flow_mod_spec: FlowModuleSpec):
#     revision_file_path = os.path.join(sync_dir, MODULE_ID_FILE_NAME)
#     with open(revision_file_path, "w") as revision_f:
#         lines = [
#             REVISION_FILE_HEADER,
#             flow_mod_spec.mod_id + "\n", # xxx/yyy:{revision}
#             flow_mod_spec.commit_hash + "\n", # commithash corresponding to the revision
#             flow_mod_spec.cache_dir + "\n", # huggingface cache_dir
#             flow_mod_spec.sync_dir + "\n"
#         ]
#         revision_f.writelines(lines)

def fetch_remote(repo_id: str, revision: str, cache_root_dir: str, sync_dir: str) -> Tuple[str, str]:
    
    sync_dir = os.path.abspath(sync_dir)
    if is_local_sync_dir_valid(sync_dir):
        remove_dir_or_link(sync_dir)

    os.makedirs(os.path.dirname(sync_dir), exist_ok=True)
    # this call is only used to download the repo to cache and get cache path
    cache_mod_dir = huggingface_hub.snapshot_download(repo_id, cache_dir=cache_root_dir, revision=revision)

    # this call will fetch the cached snapshot to the sync_dir
    huggingface_hub.snapshot_download(repo_id, cache_dir=cache_root_dir, local_dir=sync_dir, revision=revision)
    return cache_mod_dir, retrive_commit_hash_from_cache_mod_dir(cache_mod_dir)

def fetch_remote_and_write_flow_mod_spec(repo_id: str, revision: str, sync_dir: str) -> FlowModuleSpec:
    cache_dir, commit_hash = fetch_remote(repo_id, revision, DEFAULT_CACHE_PATH, sync_dir)
    flow_mod_spec = FlowModuleSpec(repo_id, revision, commit_hash, cache_dir)

    return flow_mod_spec

def fetch_local_and_write_flow_mod_spec(repo_id: str, file_path: str, sync_dir: str) -> FlowModuleSpec:
    # shutil.copytree(file_path, sync_dir, ignore=shutil.ignore_patterns(".git"), dirs_exist_ok=overwrite)
    sync_dir = os.path.abspath(sync_dir)
    # when fetch_local is triggered, the old dir is always going to be removed
    if is_local_sync_dir_valid(sync_dir):
        remove_dir_or_link(sync_dir)

    os.makedirs(os.path.dirname(sync_dir), exist_ok=True)
    os.symlink(file_path, sync_dir)

    flow_mod_spec = FlowModuleSpec(repo_id, file_path, NO_COMMIT_HASH, file_path)

    return flow_mod_spec

def is_local_sync_dir_valid(sync_dir: str):
    return os.path.isdir(sync_dir) or os.path.islink(sync_dir)

def retrive_commit_hash_from_remote(repo_id: str, revision: str) -> str:
    hf_api = HfApi()
    repo_info = hf_api.repo_info(repo_id=repo_id, repo_type="model", revision=revision, token=None)
    commit_hash = repo_info.sha
    return commit_hash

def retrive_commit_hash_from_cache_mod_dir(cache_mod_dir: str) -> str:
    return os.path.basename(cache_mod_dir)

def is_sync_dir_modified(sync_dir: str, cache_dir: str) -> bool:
    with os.scandir(cache_dir) as it:
        for entry in it:
            if entry.name.startswith('.') or entry.name == "__pycache__":
                continue

            if entry.is_file():
                same = filecmp.cmp(
                    os.path.join(cache_dir, entry.name), 
                    os.path.join(sync_dir, entry.name),
                    shallow=False
                )
                if not same:
                    logger.debug(f"File {os.path.join(cache_dir, entry.name)} is not the same as {os.path.join(sync_dir, entry.name)}")
                    return True
            elif entry.is_dir():
                dir_same = is_sync_dir_modified(
                    os.path.join(sync_dir, entry.name), 
                    os.path.join(cache_dir, entry.name)
                )
                if not dir_same:
                    return True
            else:
                raise ValueError(f"Invalid file: {os.path.join(cache_dir, entry.name)}, it is not file or dir or valid symlink")
            
    return False
            

def sync_remote_dep(previous_synced_flow_mod_spec: Optional[FlowModuleSpec], repo_id: str, mod_name: str, revision: str, caller_module_name: str, overwrite: bool = False) -> FlowModuleSpec:
    """
    Synchronizes a remote dependency.

    :param previous_synced_flow_mod_spec: The previously synced flow module specification.
    :type previous_synced_flow_mod_spec: Optional[FlowModuleSpec]
    :param repo_id: The ID of the repository.
    :type repo_id: str
    :param mod_name: The name of the module.
    :type mod_name: str
    :param revision: The revision of the module.
    :type revision: str
    :param caller_module_name: The name of the caller module.
    :type caller_module_name: str
    :param overwrite: Whether to overwrite the existing module or not. Defaults to False.
    :type overwrite: bool
    :return: The synced flow module specification.
    :rtype: FlowModuleSpec
    """
    synced_flow_mod_spec = None
    flow_mod_id = FlowModuleSpec.build_mod_id(repo_id, revision)
    sync_dir = os.path.join(os.path.curdir, DEFAULT_FLOW_MODULE_FOLDER, mod_name)

    if previous_synced_flow_mod_spec is None: # directly sync without any warning
        logger.info(f"{flow_mod_id} will be fetched from remote")
        synced_flow_mod_spec = fetch_remote_and_write_flow_mod_spec(repo_id, revision, sync_dir)
        return synced_flow_mod_spec
    
    ### we have a previously synced flow mod spec which has same **repo_id**
    assert sync_dir == previous_synced_flow_mod_spec.sync_dir, \
        (sync_dir, previous_synced_flow_mod_spec.sync_dir)
    

    # update if (revision, commit_hash) changed
    remote_revision_commit_hash_changed = False
    remote_commit_hash = retrive_commit_hash_from_remote(repo_id, revision)
    remote_revision_commit_hash_changed = remote_commit_hash != previous_synced_flow_mod_spec.commit_hash

    # check if the file is modified compared to the cache_dir
    sync_dir_modified = is_sync_dir_modified(sync_dir, previous_synced_flow_mod_spec.cache_dir)

    if overwrite:
        logger.warn(f"{colorama.Fore.RED}[{caller_module_name}] {flow_mod_id} will be overwritten, are you sure? (Y/N){colorama.Style.RESET_ALL}")
        user_input = input()
        if user_input != "Y":
            logger.warn(f"{colorama.Fore.RED}[{caller_module_name}] {flow_mod_id} will not be overwritten.{colorama.Style.RESET_ALL}")
            overwrite = False
            synced_flow_mod_spec = previous_synced_flow_mod_spec
        else:
            logger.info(f"{flow_mod_id} will be fetched from remote.{colorama.Style.RESET_ALL}")
            synced_flow_mod_spec = fetch_remote_and_write_flow_mod_spec(repo_id, revision, sync_dir)
    elif previous_synced_flow_mod_spec.mod_id != flow_mod_id:
        # user has supplied a new flow_mod_id, we fetch the remote directly with warning
        logger.warn(
                f"{colorama.Fore.RED}[{caller_module_name}] {previous_synced_flow_mod_spec.mod_id} already synced, it will be overwritten by new revision {flow_mod_id}, are you sure? (Y/N){colorama.Style.RESET_ALL}")
        user_input = input()
        if user_input != "Y":
            logger.warn(f"{colorama.Fore.RED}[{caller_module_name}] {flow_mod_id} will not be overwritten.{colorama.Style.RESET_ALL}")
            synced_flow_mod_spec = previous_synced_flow_mod_spec
        else:
           synced_flow_mod_spec =  fetch_remote_and_write_flow_mod_spec(repo_id, revision, sync_dir)
    ### user has supplied same flow_mod_id(repo_id:revision), we check if the remote commit has changed
    elif not remote_revision_commit_hash_changed:
        # trivial case, we do nothing
        logger.info(f"{flow_mod_id} already synced, skip")
        synced_flow_mod_spec = previous_synced_flow_mod_spec
    elif not sync_dir_modified:
        # remote has changed but local is not modified, we fetch the remote with a warning
        logger.warn(f"{colorama.Fore.RED}[{caller_module_name}] {previous_synced_flow_mod_spec.mod_id}'s commit hash has changed from {previous_synced_flow_mod_spec.commit_hash} to {remote_commit_hash}, as synced module is not modified, the newest commit regarding {previous_synced_flow_mod_spec.mod_id} will be fetched{colorama.Style.RESET_ALL}")
        synced_flow_mod_spec = fetch_remote_and_write_flow_mod_spec(repo_id, revision, flow_mod_id, sync_dir)
    else: 
        # synced dir is modified and remote has changed, we do nothing with a warning
        logger.warn(f"{colorama.Fore.RED}[{caller_module_name}] {previous_synced_flow_mod_spec.mod_id}'s commit hash has changed from {previous_synced_flow_mod_spec.commit_hash} to {remote_commit_hash}, but synced module is already modified, the newest commit regarding {previous_synced_flow_mod_spec.mod_id} will NOT be fetched{colorama.Style.RESET_ALL}")
        synced_flow_mod_spec = previous_synced_flow_mod_spec
        
    return synced_flow_mod_spec 

def sync_local_dep(previous_synced_flow_mod_spec: Optional[FlowModuleSpec], repo_id: str, mod_name: str, revision: str, caller_module_name: str, overwrite: bool = False) -> FlowModuleSpec:
    """
    Synchronize a local dependency.

    :param previous_synced_flow_mod_spec: The previously synced flow module specification.
    :type previous_synced_flow_mod_spec: Optional[FlowModuleSpec]
    :param repo_id: The ID of the repository.
    :type repo_id: str
    :param mod_name: The name of the module.
    :type mod_name: str
    :param revision: The revision of the module.
    :type revision: str
    :param caller_module_name: The name of the caller module.
    :type caller_module_name: str
    :param overwrite: Whether to overwrite the previously synced flow module specification. Defaults to False.
    :type overwrite: bool
    :return: The synced flow module specification.
    :rtype: FlowModuleSpec
    """

    synced_flow_mod_spec = None
    flow_mod_id = FlowModuleSpec.build_mod_id(repo_id, revision)
    module_synced_from_dir = revision
    sync_dir = os.path.join(os.path.curdir, DEFAULT_FLOW_MODULE_FOLDER, mod_name)

    if not os.path.isdir(module_synced_from_dir):
        raise ValueError(f"local dependency {flow_mod_id}'s revision {module_synced_from_dir} is not a valid local directory")

    if previous_synced_flow_mod_spec is None: # directly sync without any warning
        logger.info(f"{flow_mod_id} will be fetched from local")
        synced_flow_mod_spec = fetch_local_and_write_flow_mod_spec(repo_id, revision, sync_dir)
        return synced_flow_mod_spec

    ### we have a previously synced flow mod spec which has same **repo_id**
    assert sync_dir == previous_synced_flow_mod_spec.sync_dir, \
        (sync_dir, previous_synced_flow_mod_spec.sync_dir)

    if overwrite:
        logger.warn(f"{colorama.Fore.RED}[{caller_module_name}] {flow_mod_id} will be overwritten, are you sure? (Y/N){colorama.Style.RESET_ALL}")
        user_input = input()
        if user_input != "Y":
            logger.warn(f"{colorama.Fore.RED}[{caller_module_name}] {flow_mod_id} will not be overwritten.{colorama.Style.RESET_ALL}")
            overwrite = False
            synced_flow_mod_spec = previous_synced_flow_mod_spec
        else:
            logger.info(f"{flow_mod_id} will be fetched from local")
            synced_flow_mod_spec = fetch_local_and_write_flow_mod_spec(repo_id, module_synced_from_dir, sync_dir)

    elif previous_synced_flow_mod_spec.mod_id != flow_mod_id:
        logger.warn(
            f"{colorama.Fore.RED}[{caller_module_name}] {previous_synced_flow_mod_spec.mod_id} already synced, it will be overwritten by {flow_mod_id}, are you sure? (Y/N){colorama.Style.RESET_ALL}")
        user_input = input()
        if user_input != "Y":
            logger.warn(f"{colorama.Fore.RED}[{caller_module_name}] {previous_synced_flow_mod_spec.mod_id} will not be overwritten.{colorama.Style.RESET_ALL}")
            synced_flow_mod_spec = previous_synced_flow_mod_spec
        else:
            logger.info(f"{flow_mod_id} will be fetched from local")
            synced_flow_mod_spec = fetch_local_and_write_flow_mod_spec(repo_id, module_synced_from_dir, sync_dir)
    else:
        logger.info(f"{flow_mod_id} already synced, skip")
        synced_flow_mod_spec = previous_synced_flow_mod_spec
        
    return synced_flow_mod_spec

def create_empty_flow_mod_file(sync_root: str, overwrite: bool = False) -> str:
    flow_mod_summary_path = os.path.join(sync_root, FLOW_MODULE_SUMMARY_FILE_NAME)
    if os.path.exists(flow_mod_summary_path) and not overwrite:
        return

    with open(flow_mod_summary_path, "w") as f:
        lines = [
            REVISION_FILE_HEADER,
            f"sync_root: {sync_root}"
        ]
        f.write("\n".join(lines) + "\n")

    write_or_append_gitignore(sync_root, "w", content="*")

    return flow_mod_summary_path

def write_flow_mod_summary(flow_mod_summary_path: str, flow_mod_summary: FlowModuleSpecSummary):
    with open(flow_mod_summary_path, "w") as f:
        f.write(flow_mod_summary.serialize())
        f.write("\n")

def sync_dependencies(dependencies: List[Dict[str, str]], all_overwrite: bool = False) -> List[str]:
    caller_frame = inspect.currentframe().f_back
    caller_module = inspect.getmodule(caller_frame)
    if caller_module is None: # https://github.com/epfl-dlab/flows/issues/50
        caller_module_name = "<interactive>"
    else:
        caller_module_name = caller_module.__name__
    
    logger.info(
        f"{colorama.Fore.GREEN}[{caller_module_name}]{colorama.Style.RESET_ALL} started to sync flow module dependencies...")
    
    sync_root = os.path.abspath(os.path.join(os.path.curdir, DEFAULT_FLOW_MODULE_FOLDER))
    if not os.path.exists(sync_root):
        os.mkdir(sync_root)
    elif not os.path.isdir(sync_root):
        raise ValueError(f"flow module folder {sync_root} is not a directory")
    
    flow_mod_summary_path = create_empty_flow_mod_file(sync_root)
    flow_mod_summary = FlowModuleSpecSummary.from_flow_mod_file(flow_mod_summary_path) 

    sync_dirs = []
    for dep in dependencies:
        dep = validate_and_augment_dependency(dep, caller_module_name)
        dep_overwrite = dep.get("overwrite", False)
        dep_is_local = False
        url, revision, mod_name = dep["url"], dep["revision"], dep["mod_name"]

        if os.path.exists(revision): # revision point to a local path
            dep_is_local = True
            revision = os.path.abspath(revision)
            if DEFAULT_FLOW_MODULE_FOLDER in revision:
                raise ValueError(f"syncing a local revision from {DEFAULT_FLOW_MODULE_FOLDER} is not recommended")
        else:
            match = re.search(r"\W", revision)  # ToDo (Martin): This often fails with a cryptic error message
            if match is not None:
                raise ValueError(f"{revision} is identified as remote, as it does not exist locally. But it not a valid remote revision, it contains illegal characters: {match.group(0)}")

        synced_flow_mod_spec = None
        previous_synced_flow_mod_spec = flow_mod_summary.get_mod(url)
        if dep_is_local:
            synced_flow_mod_spec = sync_local_dep(previous_synced_flow_mod_spec, url, mod_name, revision, caller_module_name, all_overwrite or dep_overwrite)
        else:
            synced_flow_mod_spec = sync_remote_dep(previous_synced_flow_mod_spec, url, mod_name, revision, caller_module_name, all_overwrite or dep_overwrite)
        sync_dirs.append(synced_flow_mod_spec.sync_dir)
        flow_mod_summary.add_mod(synced_flow_mod_spec)

    # write flow.mod
    write_flow_mod_summary(flow_mod_summary_path, flow_mod_summary)

    logger.info(f"{colorama.Fore.GREEN}[{caller_module_name}]{colorama.Style.RESET_ALL} finished syncing\n\n")
    return sync_dirs
