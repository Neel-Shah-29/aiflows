{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7a649b1-e259-4b73-8df5-5dc7c28cae47",
   "metadata": {},
   "source": [
    "# Humans and Flows\n",
    "**In this tutorial you will:**\n",
    "- learn how humans can be represented as Flows\n",
    "- learn how Flows can request human input\n",
    "- use a simple user interface to chat with Flows\n",
    "- learn about dispatch points\n",
    "- chat with your neighbor through Flows\n",
    "\n",
    "There are many practical use cases of AI where we need to enable flexible interaction between humans and AI systems. For example, a customer support chatbot that is unable to help a customer should be able to request an internal human expert for help. A personal AI assistant booking a restaurant for a human might need to ask the human about dietary restrictions. In general, when an AI agent encounters a roadblock - it should be able to reach out to humans for help.\n",
    "\n",
    "Furthermore, humans can be used to help AI systems with tasks that require complex reasoning. One such example is competitive programming - given a competitive programming problem, an LLM might struggle to solve it on it's own. However, we can include a human in the loop by having it provide a high-level plan on how to solve a given problem. We have implemented this particular example using aiFlows - learn more about it [here](https://huggingface.co/aiflows/CCFlows).\n",
    "\n",
    "Depending on the workflow you are trying to automate, you might want to have a human \"chip in\" at certain places and under certain conditions. This is particularly important at the early stages of integrating AI into your business.\n",
    "\n",
    "**In aiFlows, we view humans as tools that are simply wrapped with a Flow abstraction. This allows us to treat a human as any other regular Flow, enabling us to easily create complex interactions between humans and AI systems.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3290339a-e045-465a-a503-03dece48822a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolasbaldwin/opt/miniconda3/envs/mockenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, json, copy\n",
    "from colink import CoLink\n",
    "from aiflows.utils import serve_utils\n",
    "from aiflows.utils.general_helpers import read_yaml_file\n",
    "from aiflows.messages import FlowMessage\n",
    "from aiflows.utils import coflows_utils, colink_utils\n",
    "from aiflows.workers import run_dispatch_worker_thread, run_get_instance_worker_thread\n",
    "from aiflows.backends.api_info import ApiInfo\n",
    "from aiflows import flow_verse\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils import compile_and_writefile, dict_to_yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f88142-d741-4f58-87bc-da87923de3d1",
   "metadata": {},
   "source": [
    "## HumanFlow\n",
    "\n",
    "A Flow designed to encapsulate a human will simply relay received messages to the human and then transmit the human's response back to the original sender. We can essentially think of a human as being the implementation of the Flow's ```run()``` method. We refer to such flow as a \"HumanFlow\". \n",
    "\n",
    "In this notebook we will demonstrate how to run a simple chat interaction between a human and a chabot using aiFlows. We will facilitate the interaction as a Composite Flow that has two subflows: a ChatFlow and a HumanFlow. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a894bf-5605-4da7-984d-d0e06ee3288e",
   "metadata": {},
   "source": [
    "## Connect to CoLink Server\n",
    "\n",
    "To run this example, we will need a CoLink server running outside of the notebook because we will need to start the human UI in a separate process.\n",
    "\n",
    "You can run the example by connecting to our official CoLink server or by starting a local CoLink server instance in a separate shell.\n",
    "If you wish to run locally, please install the latest server release from here: https://github.com/CoLearn-Dev/colink-server-dev/releases\n",
    "\n",
    "We will continue by connecting to our hosted CoLink server. If you don't have a colink user with our server, please do the following:\n",
    "\n",
    "Run ```python generate_user.py``` (or run the cell bellow)\n",
    "\n",
    "This will generate your key pair and a signature of your intent to register with our server. The script will generate a file called user.txt which will contain your pubkey and signature. You should then provide this file to our server administrators - they will create a JWT for you, allowing you to connect to our CoLink server. Feel free to share this file with us through our [Discord](https://discord.gg/UbQ5JYtP)!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75d5df03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created colink user. Please share the generated user.txt file with the server admin.\n"
     ]
    }
   ],
   "source": [
    "!cd .. && python generate_user.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5454629-74ae-4fc4-8b1e-244ae25184c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "025e1f6940ed7c170a6b1f9a9f5f8cfbfa778a3d13e88a484c719968312520c1bb\n"
     ]
    }
   ],
   "source": [
    "addr = \"https://amld.colink-server.colearn.cloud\"\n",
    "jwt = \"eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJwcml2aWxlZ2UiOiJ1c2VyIiwidXNlcl9pZCI6IjAyNWUxZjY5NDBlZDdjMTcwYTZiMWY5YTlmNWY4Y2ZiZmE3NzhhM2QxM2U4OGE0ODRjNzE5OTY4MzEyNTIwYzFiYiIsImV4cCI6MTcxMzg2NDg0OX0.2zy5SuJlr5Go4dHmuCcOL9n0uJ4OVOf0pfUlIakjHY4\" # YOUR JWT\n",
    "\n",
    "cl = CoLink(addr, jwt)\n",
    "print(cl.get_user_id())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d8604c-1779-45cc-8325-67c8c47745b1",
   "metadata": {},
   "source": [
    "## ChatFlows UI\n",
    "\n",
    "We have prepared a simple script that serves an AtomicFlow wrapper around a human, and starts a user interface through which the human can reply to messages directed at that flow, termed the HumanFlow. For practical use, you can integrate HumanFlows into your frontend applications by running a background CoLink worker process that receives messages sent to the HumanFlow and triggers an event in your application.\n",
    "\n",
    "To serve the HumanFlow and start the UI:\n",
    "- navigate to the /chatflows-ui folder\n",
    "- add your JWT to the ui-config.yaml file\n",
    "- run the application with ```streamlit run chatflows-ui.py```\n",
    "\n",
    "While you are there, take a peek at the HumanUIFlow.yaml file which contains the flow config for the HumanFlow.\n",
    "\n",
    "We have now served the HumanFlow as a singleton under the flow endpoint \"User\" (you can modify the endpoint in ui-config.yaml). We can now use the HumanFlow as a subflow of a larger Composite Flow, or we can directly interact with it by obtaining a proxy - let's do that first to ensure everything works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbc3a626-65ba-4abc-9376-7ed637f64b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2024-03-23 03:00:02,625\u001b[0m][\u001b[34maiflows.utils.serve_utils:543\u001b[0m][\u001b[32mINFO\u001b[0m] - Fetched singleton a4dc0076-1daa-4117-907e-09a48ab5cefb\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'human_input': \"Yes I'm here!!!\"}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_flow = serve_utils.get_flow_instance(\n",
    "    cl=cl,\n",
    "    flow_endpoint=\"User\",\n",
    ")\n",
    "input_data = {\"id\": 0, \"api_output\": \"Human, are you there?\"}\n",
    "input_message = user_flow.package_input_message(input_data)\n",
    "\n",
    "user_flow.get_reply_future(input_message).get_data() # blocks until human responds via UI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062c37a4-3f8c-4587-89f9-4fe8e16e28ab",
   "metadata": {},
   "source": [
    "Since CoLink allows us to invoke Flows served by other users, you can also invoke another user's HumanFlow! You just need to plug in their colink user ID when getting the flow instance. Just make sure that you are both running get_instance workers needed for getting/serving flow instances across users (note that running the UI automatically starts a get_instance worker in the background)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1672c4a1-0582-4df4-97ca-1317242b38fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you don't have the UI running, uncomment and run the line below\n",
    "# run_get_instance_worker_thread(cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c605fb1-a40c-4d95-94ae-8257ff67460f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'human_input': 'Hey there neighbor!!'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_flow = serve_utils.get_flow_instance(\n",
    "    cl=cl,\n",
    "    flow_endpoint=\"User\",\n",
    "    user_id=... # Your neighbor's CoLink user ID\n",
    ")\n",
    "\n",
    "input_data = {\"id\": 0, \"api_output\": \"Neighbor, are you there?\"}\n",
    "input_message = user_flow.package_input_message(input_data)\n",
    "\n",
    "user_flow.get_reply_future(input_message).get_data() # blocks until human responds via UI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f51cd3b-9ac1-4a88-8c5e-e5b20a49981b",
   "metadata": {},
   "source": [
    "## Orchestrating the interaction\n",
    "\n",
    "Now let's try orchestrating a back and forth interaction between a ChatFlow and a HumanFlow. We start by fetching necessary Flows from the FlowVerse and serving them. The ChatHumanFlowModule is a simple composite flow that relays messages between it's two subflows (ChatAtomicFlow and HumanFlow), facilitating the \"chat\" interaction between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be9b9f3b-55a3-4a30-80eb-d8b5458de1ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2024-03-23 12:11:13,818\u001b[0m][\u001b[34maiflows.flow_verse.loading:775\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m[<interactive>]\u001b[0m started to sync flow module dependencies to /Users/nicolasbaldwin/Documents/OneDrive/EPFL/DLAB/aiflow-colink/aiflows/AMLD/AMLD_Workshop/5.Human/flow_modules...\u001b[0m\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "('/Users/nicolasbaldwin/Documents/OneDrive/EPFL/DLAB/aiflow-colink/aiflows/AMLD/AMLD_Workshop/5.Human/flow_modules/aiflows/ChatFlowModule', '/Users/nicolasbaldwin/Documents/OneDrive/EPFL/DLAB/aiflow-colink/aiflows/AMLD/Human/flow_modules/aiflows/ChatFlowModule')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m dependencies \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maiflows/ChatFlowModule\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrevision\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m      3\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maiflows/ChatInteractiveFlowModule\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrevision\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m      4\u001b[0m ]\n\u001b[0;32m----> 5\u001b[0m \u001b[43mflow_verse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_dependencies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdependencies\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/mockenv/lib/python3.11/site-packages/aiflows/flow_verse/loading.py:846\u001b[0m, in \u001b[0;36msync_dependencies\u001b[0;34m(dependencies, all_overwrite)\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    844\u001b[0m     caller_module_name \u001b[38;5;241m=\u001b[39m caller_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m--> 846\u001b[0m flow_mod_summary \u001b[38;5;241m=\u001b[39m \u001b[43m_sync_dependencies\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdependencies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_overwrite\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEFAULT_CACHE_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaller_module_name\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [mod\u001b[38;5;241m.\u001b[39msync_dir \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m flow_mod_summary\u001b[38;5;241m.\u001b[39mget_mods()]\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/mockenv/lib/python3.11/site-packages/aiflows/flow_verse/loading.py:808\u001b[0m, in \u001b[0;36m_sync_dependencies\u001b[0;34m(dependencies, all_overwrite, flow_modules_base_dir, cache_root, caller_module_name)\u001b[0m\n\u001b[1;32m    797\u001b[0m     synced_flow_mod_spec \u001b[38;5;241m=\u001b[39m sync_local_dep(\n\u001b[1;32m    798\u001b[0m         previous_synced_flow_mod_spec,\n\u001b[1;32m    799\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    804\u001b[0m         all_overwrite \u001b[38;5;129;01mor\u001b[39;00m dep_overwrite,\n\u001b[1;32m    805\u001b[0m     )\n\u001b[1;32m    806\u001b[0m     \u001b[38;5;66;03m# logger.debug(f\"add local dep {synced_flow_mod_spec} to flow_mod_summary\")\u001b[39;00m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 808\u001b[0m     synced_flow_mod_spec \u001b[38;5;241m=\u001b[39m \u001b[43msync_remote_dep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    809\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprevious_synced_flow_mod_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    811\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmod_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    813\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcaller_module_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    814\u001b[0m \u001b[43m        \u001b[49m\u001b[43msync_root\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    815\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_root\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    816\u001b[0m \u001b[43m        \u001b[49m\u001b[43mall_overwrite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdep_overwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    817\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    818\u001b[0m     \u001b[38;5;66;03m# logger.debug(f\"add remote dep {synced_flow_mod_spec} to flow_mod_summary\")\u001b[39;00m\n\u001b[1;32m    819\u001b[0m flow_mod_summary\u001b[38;5;241m.\u001b[39madd_mod(synced_flow_mod_spec)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/mockenv/lib/python3.11/site-packages/aiflows/flow_verse/loading.py:568\u001b[0m, in \u001b[0;36msync_remote_dep\u001b[0;34m(previous_synced_flow_mod_spec, repo_id, mod_name, revision, caller_module_name, sync_root, cache_root, overwrite)\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m synced_flow_mod_spec\n\u001b[1;32m    567\u001b[0m \u001b[38;5;66;03m### we have a previously synced flow mod spec which has same **repo_id**\u001b[39;00m\n\u001b[0;32m--> 568\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m sync_dir \u001b[38;5;241m==\u001b[39m previous_synced_flow_mod_spec\u001b[38;5;241m.\u001b[39msync_dir, (sync_dir, previous_synced_flow_mod_spec\u001b[38;5;241m.\u001b[39msync_dir)\n\u001b[1;32m    570\u001b[0m \u001b[38;5;66;03m# update if (revision, commit_hash) changed\u001b[39;00m\n\u001b[1;32m    571\u001b[0m remote_revision_commit_hash_changed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: ('/Users/nicolasbaldwin/Documents/OneDrive/EPFL/DLAB/aiflow-colink/aiflows/AMLD/AMLD_Workshop/5.Human/flow_modules/aiflows/ChatFlowModule', '/Users/nicolasbaldwin/Documents/OneDrive/EPFL/DLAB/aiflow-colink/aiflows/AMLD/Human/flow_modules/aiflows/ChatFlowModule')"
     ]
    }
   ],
   "source": [
    "dependencies = [\n",
    "    {\"url\": \"aiflows/ChatFlowModule\", \"revision\": \"main\"},\n",
    "    {\"url\": \"aiflows/ChatInteractiveFlowModule\", \"revision\": \"main\"}\n",
    "]\n",
    "flow_verse.sync_dependencies(dependencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c8767fe-5d4b-48bd-99e8-54b196c62b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2024-03-23 03:03:17,812\u001b[0m][\u001b[34maiflows.utils.serve_utils:116\u001b[0m][\u001b[32mINFO\u001b[0m] - Started serving flow_modules.aiflows.ChatFlowModule.ChatAtomicFlow at flows:Assistant.\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:03:17,813\u001b[0m][\u001b[34maiflows.utils.serve_utils:117\u001b[0m][\u001b[32mINFO\u001b[0m] - dispatch_point: assistant_dispatch\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:03:17,813\u001b[0m][\u001b[34maiflows.utils.serve_utils:118\u001b[0m][\u001b[32mINFO\u001b[0m] - parallel_dispatch: False\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:03:17,814\u001b[0m][\u001b[34maiflows.utils.serve_utils:119\u001b[0m][\u001b[32mINFO\u001b[0m] - singleton: False\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:03:21,845\u001b[0m][\u001b[34maiflows.utils.serve_utils:116\u001b[0m][\u001b[32mINFO\u001b[0m] - Started serving flow_modules.aiflows.ChatInteractiveFlowModule.ChatHumanFlowModule at flows:InteractiveChat.\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:03:21,846\u001b[0m][\u001b[34maiflows.utils.serve_utils:117\u001b[0m][\u001b[32mINFO\u001b[0m] - dispatch_point: coflows_dispatch\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:03:21,846\u001b[0m][\u001b[34maiflows.utils.serve_utils:118\u001b[0m][\u001b[32mINFO\u001b[0m] - parallel_dispatch: False\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:03:21,847\u001b[0m][\u001b[34maiflows.utils.serve_utils:119\u001b[0m][\u001b[32mINFO\u001b[0m] - singleton: False\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serve_utils.serve_flow(\n",
    "    cl=cl,\n",
    "    flow_class_name=\"flow_modules.aiflows.ChatFlowModule.ChatAtomicFlow\",\n",
    "    flow_endpoint=\"Assistant\",\n",
    "    dispatch_point=\"assistant_dispatch\"\n",
    ")\n",
    "serve_utils.serve_flow(\n",
    "    cl=cl,\n",
    "    flow_class_name=\"flow_modules.aiflows.ChatInteractiveFlowModule.ChatHumanFlowModule\",\n",
    "    flow_endpoint=\"InteractiveChat\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcfbf06-a936-4eba-9981-9762813656df",
   "metadata": {},
   "source": [
    "### Dispatch points\n",
    "\n",
    "Notice that we served the ChatAtomicFlow under the dispatch point \"assistant_dispatch\". Dispatch points act as the decoupling mechanism between workers (which execute the Flows) and the scheduler (which schedules Flows for execution). When a Flow receives a message, the scheduler will schedule it's execution on one of the workers that is attached to the dispatch point specified in the serve_flow call. The dispatch point simply tells the scheduler where to dispatch Flow execution requests.\n",
    "\n",
    "Dispatch points allow you to define multiple worker groups where each group can be assigned to execute different Flows. You can use this to designate resources to specific Flows, run Flows in different execution environments, etc.\n",
    "\n",
    "We will start two dispatch workers - one attached to the default dispatch point, and one attached to the \"assistant_dispatch\" point. We will pass our OpenAI API info to the second one - this worker will then inject the API info when loading the ChatAtomicFlow for execution - we do this for privacy reasons, so that the API info doesn't get stored in CoLink storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b30b590-d2d2-4fc8-b75b-3b54cb8777d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2024-03-23 03:06:12,991\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:235\u001b[0m][\u001b[32mINFO\u001b[0m] - Dispatch worker started in attached thread.\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:06:13,006\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:236\u001b[0m][\u001b[32mINFO\u001b[0m] - dispatch_point: coflows_dispatch\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:06:13,009\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:235\u001b[0m][\u001b[32mINFO\u001b[0m] - Dispatch worker started in attached thread.\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:06:13,010\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:236\u001b[0m][\u001b[32mINFO\u001b[0m] - dispatch_point: assistant_dispatch\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:06:45,952\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:119\u001b[0m][\u001b[32mINFO\u001b[0m] - \n",
      "~~~ Dispatch task ~~~\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:06:47,301\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:161\u001b[0m][\u001b[32mINFO\u001b[0m] - flow_endpoint: InteractiveChat\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:06:47,302\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:162\u001b[0m][\u001b[32mINFO\u001b[0m] - flow_id: 089f6bd0-1752-4cb8-ba79-fe4a80676e30\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:06:47,303\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:163\u001b[0m][\u001b[32mINFO\u001b[0m] - owner_id: local\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:06:47,303\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:164\u001b[0m][\u001b[32mINFO\u001b[0m] - message_paths: ['push_tasks:a9e509b8-6a81-4c09-8438-481561d0e0cf:msg']\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:06:47,304\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:165\u001b[0m][\u001b[32mINFO\u001b[0m] - parallel_dispatch: False\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:06:49,347\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:188\u001b[0m][\u001b[32mINFO\u001b[0m] - Input message source: Proxy_InteractiveChat\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:06:51,710\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:119\u001b[0m][\u001b[32mINFO\u001b[0m] - \n",
      "~~~ Dispatch task ~~~\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:06:53,064\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:161\u001b[0m][\u001b[32mINFO\u001b[0m] - flow_endpoint: Assistant\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:06:53,065\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:162\u001b[0m][\u001b[32mINFO\u001b[0m] - flow_id: f9705080-b4d9-417a-a1e4-bb9eda0c5f0a\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:06:53,066\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:163\u001b[0m][\u001b[32mINFO\u001b[0m] - owner_id: local\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:06:53,067\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:164\u001b[0m][\u001b[32mINFO\u001b[0m] - message_paths: ['push_tasks:24ad30ee-37ae-4c11-8a0c-87c4e41de9fe:msg']\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:06:53,067\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:165\u001b[0m][\u001b[32mINFO\u001b[0m] - parallel_dispatch: False\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:06:55,191\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:188\u001b[0m][\u001b[32mINFO\u001b[0m] - Input message source: Assistant\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:06:58,404\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:119\u001b[0m][\u001b[32mINFO\u001b[0m] - \n",
      "~~~ Dispatch task ~~~\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:06:59,738\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:161\u001b[0m][\u001b[32mINFO\u001b[0m] - flow_endpoint: InteractiveChat\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:06:59,739\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:162\u001b[0m][\u001b[32mINFO\u001b[0m] - flow_id: 089f6bd0-1752-4cb8-ba79-fe4a80676e30\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:06:59,739\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:163\u001b[0m][\u001b[32mINFO\u001b[0m] - owner_id: local\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:06:59,739\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:164\u001b[0m][\u001b[32mINFO\u001b[0m] - message_paths: ['push_tasks:21e75b50-1a3b-41c3-99ac-ba0c78ed6b9c:msg']\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:06:59,740\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:165\u001b[0m][\u001b[32mINFO\u001b[0m] - parallel_dispatch: False\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:07:01,793\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:188\u001b[0m][\u001b[32mINFO\u001b[0m] - Input message source: Assistant\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:07:52,555\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:119\u001b[0m][\u001b[32mINFO\u001b[0m] - \n",
      "~~~ Dispatch task ~~~\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:07:53,912\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:161\u001b[0m][\u001b[32mINFO\u001b[0m] - flow_endpoint: InteractiveChat\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:07:53,913\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:162\u001b[0m][\u001b[32mINFO\u001b[0m] - flow_id: 089f6bd0-1752-4cb8-ba79-fe4a80676e30\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:07:53,914\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:163\u001b[0m][\u001b[32mINFO\u001b[0m] - owner_id: local\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:07:53,914\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:164\u001b[0m][\u001b[32mINFO\u001b[0m] - message_paths: ['push_tasks:daf18214-cf83-4794-bac5-bc44f2b6fb9a:msg']\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:07:53,915\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:165\u001b[0m][\u001b[32mINFO\u001b[0m] - parallel_dispatch: False\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:07:56,052\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:188\u001b[0m][\u001b[32mINFO\u001b[0m] - Input message source: HumanUIFlow\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:07:58,383\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:119\u001b[0m][\u001b[32mINFO\u001b[0m] - \n",
      "~~~ Dispatch task ~~~\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:07:59,718\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:161\u001b[0m][\u001b[32mINFO\u001b[0m] - flow_endpoint: Assistant\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:07:59,719\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:162\u001b[0m][\u001b[32mINFO\u001b[0m] - flow_id: f9705080-b4d9-417a-a1e4-bb9eda0c5f0a\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:07:59,720\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:163\u001b[0m][\u001b[32mINFO\u001b[0m] - owner_id: local\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:07:59,720\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:164\u001b[0m][\u001b[32mINFO\u001b[0m] - message_paths: ['push_tasks:144fe3c3-d285-41a5-8163-0aed7aba24b3:msg']\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:07:59,721\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:165\u001b[0m][\u001b[32mINFO\u001b[0m] - parallel_dispatch: False\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:08:01,765\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:188\u001b[0m][\u001b[32mINFO\u001b[0m] - Input message source: Assistant\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:08:06,230\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:119\u001b[0m][\u001b[32mINFO\u001b[0m] - \n",
      "~~~ Dispatch task ~~~\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:08:07,565\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:161\u001b[0m][\u001b[32mINFO\u001b[0m] - flow_endpoint: InteractiveChat\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:08:07,566\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:162\u001b[0m][\u001b[32mINFO\u001b[0m] - flow_id: 089f6bd0-1752-4cb8-ba79-fe4a80676e30\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:08:07,567\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:163\u001b[0m][\u001b[32mINFO\u001b[0m] - owner_id: local\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:08:07,567\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:164\u001b[0m][\u001b[32mINFO\u001b[0m] - message_paths: ['push_tasks:a93f8faa-9a90-47e7-8ef0-8c1b3a3196fa:msg']\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:08:07,567\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:165\u001b[0m][\u001b[32mINFO\u001b[0m] - parallel_dispatch: False\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:08:09,629\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:188\u001b[0m][\u001b[32mINFO\u001b[0m] - Input message source: Assistant\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:08:22,679\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:119\u001b[0m][\u001b[32mINFO\u001b[0m] - \n",
      "~~~ Dispatch task ~~~\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:08:24,050\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:161\u001b[0m][\u001b[32mINFO\u001b[0m] - flow_endpoint: InteractiveChat\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:08:24,051\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:162\u001b[0m][\u001b[32mINFO\u001b[0m] - flow_id: 089f6bd0-1752-4cb8-ba79-fe4a80676e30\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:08:24,051\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:163\u001b[0m][\u001b[32mINFO\u001b[0m] - owner_id: local\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:08:24,052\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:164\u001b[0m][\u001b[32mINFO\u001b[0m] - message_paths: ['push_tasks:afd8379c-6248-4198-8403-851756317c9f:msg']\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:08:24,052\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:165\u001b[0m][\u001b[32mINFO\u001b[0m] - parallel_dispatch: False\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:08:26,078\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:188\u001b[0m][\u001b[32mINFO\u001b[0m] - Input message source: HumanUIFlow\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:08:26,079\u001b[0m][\u001b[34maiflows.data_transformations.end_of_interaction:40\u001b[0m][\u001b[32mINFO\u001b[0m] - End of interaction detected!\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:08:26,080\u001b[0m][\u001b[34maiflows.utils.coflows_utils:120\u001b[0m][\u001b[32mINFO\u001b[0m] - no_reply mode\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:09:30,453\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:119\u001b[0m][\u001b[32mINFO\u001b[0m] - \n",
      "~~~ Dispatch task ~~~\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:09:31,787\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:161\u001b[0m][\u001b[32mINFO\u001b[0m] - flow_endpoint: Human2Human\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:09:31,788\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:162\u001b[0m][\u001b[32mINFO\u001b[0m] - flow_id: c0728d7e-4d58-42c0-8943-269c08e7c002\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:09:31,788\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:163\u001b[0m][\u001b[32mINFO\u001b[0m] - owner_id: local\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:09:31,789\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:164\u001b[0m][\u001b[32mINFO\u001b[0m] - message_paths: ['push_tasks:402b1f04-cdae-46f5-819d-1e2bc5b9d224:msg']\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:09:31,789\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:165\u001b[0m][\u001b[32mINFO\u001b[0m] - parallel_dispatch: False\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:09:33,861\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:188\u001b[0m][\u001b[32mINFO\u001b[0m] - Input message source: Proxy_Human2Human\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:09:57,608\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:119\u001b[0m][\u001b[32mINFO\u001b[0m] - \n",
      "~~~ Dispatch task ~~~\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:09:58,944\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:161\u001b[0m][\u001b[32mINFO\u001b[0m] - flow_endpoint: Human2Human\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:09:58,945\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:162\u001b[0m][\u001b[32mINFO\u001b[0m] - flow_id: c0728d7e-4d58-42c0-8943-269c08e7c002\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:09:58,946\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:163\u001b[0m][\u001b[32mINFO\u001b[0m] - owner_id: local\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:09:58,947\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:164\u001b[0m][\u001b[32mINFO\u001b[0m] - message_paths: ['push_tasks:e69c00b0-375f-4e91-837b-83ec864fac1b:msg']\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:09:58,947\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:165\u001b[0m][\u001b[32mINFO\u001b[0m] - parallel_dispatch: False\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:10:01,013\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:188\u001b[0m][\u001b[32mINFO\u001b[0m] - Input message source: HumanUIFlow\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:10:15,607\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:119\u001b[0m][\u001b[32mINFO\u001b[0m] - \n",
      "~~~ Dispatch task ~~~\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:10:16,959\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:161\u001b[0m][\u001b[32mINFO\u001b[0m] - flow_endpoint: Human2Human\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:10:16,960\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:162\u001b[0m][\u001b[32mINFO\u001b[0m] - flow_id: c0728d7e-4d58-42c0-8943-269c08e7c002\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:10:16,960\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:163\u001b[0m][\u001b[32mINFO\u001b[0m] - owner_id: local\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:10:16,961\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:164\u001b[0m][\u001b[32mINFO\u001b[0m] - message_paths: ['push_tasks:82cf8ba9-d198-45d9-a091-2023a57af856:msg']\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:10:16,961\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:165\u001b[0m][\u001b[32mINFO\u001b[0m] - parallel_dispatch: False\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:10:19,000\u001b[0m][\u001b[34maiflows.workers.dispatch_worker:188\u001b[0m][\u001b[32mINFO\u001b[0m] - Input message source: HumanUIFlow\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# this worker will execute ChatHumanFlowModule\n",
    "run_dispatch_worker_thread(cl)\n",
    "\n",
    "# this worker will execute ChatAtomicFlow\n",
    "run_dispatch_worker_thread(\n",
    "    cl, \n",
    "    dispatch_point=\"assistant_dispatch\",\n",
    "    api_infos=[ApiInfo(backend_used=\"openai\", api_key=os.getenv(\"OPENAI_API_KEY\"))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be8a06f6-e6a9-4d23-847d-72ec5e6061f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2024-03-23 03:06:18,832\u001b[0m][\u001b[34maiflows.flow_verse.loading:775\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m[flow_modules.aiflows.ChatInteractiveFlowModule]\u001b[0m started to sync flow module dependencies to /home/staverm/workspace/coflows-dev/aiflows/AMLD/AMLD_Workshop/5.Human/flow_modules...\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:06:18,928\u001b[0m][\u001b[34maiflows.flow_verse.loading:608\u001b[0m][\u001b[32mINFO\u001b[0m] - aiflows/ChatFlowModule:main already synced, skip\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:06:18,930\u001b[0m][\u001b[34maiflows.flow_verse.loading:563\u001b[0m][\u001b[32mINFO\u001b[0m] - aiflows/HumanStandardInputFlowModule:main will be fetched from remote\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baf32ec1751545e7a32396c80a0dfd42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30a9184f373e40879664b8f6d6914aa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2024-03-23 03:06:19,149\u001b[0m][\u001b[34maiflows.flow_verse.loading:825\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m[flow_modules.aiflows.ChatInteractiveFlowModule]\u001b[0m finished syncing\n",
      "\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:06:24,580\u001b[0m][\u001b[34maiflows.utils.serve_utils:336\u001b[0m][\u001b[32mINFO\u001b[0m] - Mounted f9705080-b4d9-417a-a1e4-bb9eda0c5f0a at flows:Assistant:mounts:local:f9705080-b4d9-417a-a1e4-bb9eda0c5f0a\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:06:27,941\u001b[0m][\u001b[34maiflows.utils.serve_utils:543\u001b[0m][\u001b[32mINFO\u001b[0m] - Fetched singleton a4dc0076-1daa-4117-907e-09a48ab5cefb\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:06:31,309\u001b[0m][\u001b[34maiflows.utils.serve_utils:336\u001b[0m][\u001b[32mINFO\u001b[0m] - Mounted 089f6bd0-1752-4cb8-ba79-fe4a80676e30 at flows:InteractiveChat:mounts:local:089f6bd0-1752-4cb8-ba79-fe4a80676e30\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# fetch instance of ChatHumanFlowModule, make sure you have started the UI\n",
    "interactive_chat = serve_utils.get_flow_instance(\n",
    "    cl=cl,\n",
    "    flow_endpoint=\"InteractiveChat\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0d07a3-fdbe-4970-84f4-0e363ee583c5",
   "metadata": {},
   "source": [
    "We will kickstart the chat interaction by sending a message to the Composite Flow which will first relay this message to the Assistant, and then relay the Assistant's output message to our HumanFlow - this message should then get displayed in your UI. After receiving the message, you can respond to it via the UI and keep chatting with the Assistant. You can stop the chat orchestration by typing \\<END>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed97131e-339b-4612-a007-6a44247967b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = interactive_chat.package_input_message(\n",
    "    {\"id\": 0, \"query\": \"I want to ask you a few questions\"},\n",
    ")\n",
    "interactive_chat.send_message(input_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bfbc91",
   "metadata": {},
   "source": [
    "## Human to Human chat\n",
    "\n",
    "Similarly to the example above, we can orchestrate a chat interaction between two HumanFlows (through the UI). Find a partner that is also connected to our CoLink server and go through the rest of the notebook together. \n",
    "\n",
    "We will create a simple Composite Flow to facilitate the Human to Human interaction (similar to the ChatHumanFlowModule we used above). See it's implementation and default config below. This Flow is essentially a state machine that alternates between two states, representing two users (\"User1\" and \"User2\"). It directs the flow of messages between these users, ensuring that communication is alternated between them based on the last state recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4c706da-8f73-47f2-801e-f42e8ad02781",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%compile_and_writefile HumanToHumanFlowModule/HumanToHuman.py\n",
    "\n",
    "from aiflows.base_flows import CompositeFlow\n",
    "from aiflows.messages import FlowMessage\n",
    "from aiflows.interfaces import KeyInterface\n",
    "\n",
    "\n",
    "class HumanToHuman(CompositeFlow):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.input_interface = KeyInterface(\n",
    "            keys_to_rename={\"human_input\": \"api_output\"}\n",
    "        )\n",
    "        self.flow_state[\"last_state\"] = None\n",
    "\n",
    "    def call_user(self, user, input_message: FlowMessage):\n",
    "        message = self.input_interface(input_message)\n",
    "        message = self.package_input_message(data=message.data)\n",
    "\n",
    "        self.subflows[user].get_reply(message)\n",
    "\n",
    "    def run(self, input_message: FlowMessage):\n",
    "        last_state = self.flow_state[\"last_state\"]\n",
    "\n",
    "        if last_state is None or last_state == \"User2\":\n",
    "            self.call_user(user=\"User1\", input_message=input_message)\n",
    "            self.flow_state[\"last_state\"] = \"User1\"\n",
    "\n",
    "        elif last_state == \"User1\":\n",
    "            self.call_user(user=\"User2\", input_message=input_message)\n",
    "            self.flow_state[\"last_state\"] = \"User2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "438b03ca-6c44-452b-a7d6-1c8c339a84d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "human2human_default_config = {\n",
    "    \"name\": \"Human2HumanInteractiveFlow\",\n",
    "    \"description\": \"Flow that enables chatting between two Human users.\",\n",
    "    \"_target_\": \"HumanToHumanFlowModule.HumanToHuman.HumanToHuman.instantiate_from_default_config\",\n",
    "    \"subflows_config\": {\n",
    "        \"User1\": {\n",
    "            \"name\": \"User1\",\n",
    "            \"description\": \"A flow that represents the first user.\",\n",
    "            \"flow_endpoint\": \"User\",\n",
    "            \"user_id\": \"local\"\n",
    "        },\n",
    "        \"User2\": {\n",
    "            \"name\": \"User2\",\n",
    "            \"description\": \"A flow that represents the second user.\",\n",
    "            \"flow_endpoint\": \"User\",\n",
    "            \"user_id\": \"???\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "dict_to_yaml(human2human_default_config, \"HumanToHumanFlowModule/HumanToHuman.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5ee0ef-29c6-4390-9859-1b647c421215",
   "metadata": {},
   "source": [
    "Decide with your partner who will orchestrate the interaction and let them run the cells below. Both of you should have the UI running and connected to our CoLink server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8c26ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2024-03-23 03:08:42,329\u001b[0m][\u001b[34maiflows.utils.serve_utils:116\u001b[0m][\u001b[32mINFO\u001b[0m] - Started serving HumanToHumanFlowModule.HumanToHuman.HumanToHuman at flows:Human2Human.\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:08:42,330\u001b[0m][\u001b[34maiflows.utils.serve_utils:117\u001b[0m][\u001b[32mINFO\u001b[0m] - dispatch_point: coflows_dispatch\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:08:42,330\u001b[0m][\u001b[34maiflows.utils.serve_utils:118\u001b[0m][\u001b[32mINFO\u001b[0m] - parallel_dispatch: False\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:08:42,331\u001b[0m][\u001b[34maiflows.utils.serve_utils:119\u001b[0m][\u001b[32mINFO\u001b[0m] - singleton: False\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serve_utils.serve_flow(\n",
    "    cl=cl,\n",
    "    flow_class_name=\"HumanToHumanFlowModule.HumanToHuman.HumanToHuman\",\n",
    "    flow_endpoint=\"Human2Human\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1378e6-b15e-445b-8512-a619a9ecbc23",
   "metadata": {},
   "source": [
    "Notice that user_id of User2 was intentionally left empty in the default config. Ask your partner to share their CoLink user_id with you and we will inject it as an override when getting an instance of the HumanToHuman Flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d7172d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "user2_id = ... # Your partner's CoLink user id\n",
    "config_overrides = {\n",
    "    \"subflows_config\": {\n",
    "        \"User2\": {\n",
    "            \"user_id\": user2_id\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1a27d35-b4c5-45a4-902c-e919b053a541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2024-03-23 03:09:03,452\u001b[0m][\u001b[34maiflows.utils.serve_utils:543\u001b[0m][\u001b[32mINFO\u001b[0m] - Fetched singleton a4dc0076-1daa-4117-907e-09a48ab5cefb\u001b[0m\n",
      "[\u001b[36m2024-03-23 03:09:22,104\u001b[0m][\u001b[34maiflows.utils.serve_utils:336\u001b[0m][\u001b[32mINFO\u001b[0m] - Mounted c0728d7e-4d58-42c0-8943-269c08e7c002 at flows:Human2Human:mounts:local:c0728d7e-4d58-42c0-8943-269c08e7c002\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "human2human_chat = serve_utils.get_flow_instance(\n",
    "    cl=cl,\n",
    "    flow_endpoint=\"Human2Human\",\n",
    "    config_overrides=config_overrides\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d623d1ed-4e0e-41b3-a055-d28a4c07eca1",
   "metadata": {},
   "source": [
    "Ensure you have a dispatch worker running at the default dispatch point (you should have one from before) - it will execute the Human2Human Flow we just mounted.\n",
    "\n",
    "Everything is ready! We can kickstart the chat interaction by sending a message to our instance of the Human2Human Flow. After that you should be able to chat with your partner through the UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a1cd576",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = human2human_chat.package_input_message(\n",
    "    {\"id\": 0, \"api_output\": \"Let's start chatting.\"},\n",
    ")\n",
    "human2human_chat.send_message(input_message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
